<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Building a Persistent AI Thought Partner with Memory and State | Amy Jerkovich</title>
    <meta name="description" content="How I architected an AI agent capable of navigating the web.">
    <link rel="stylesheet" href="css/styles.css">
</head>

<body>
    <nav>
        <div class="logo">Amy Jerkovich</div>
        <div class="nav-links">
            <a href="index.html">Home</a>
            <a href="index.html#projects" class="active">Projects</a>
            <a href="about.html">About</a>
        </div>
    </nav>

    <article class="post-container">
        <header class="post-header fade-up">
            <div
                style="color: var(--accent-color); font-weight: 600; text-transform: uppercase; letter-spacing: 1px; margin-bottom: 1rem;">
                Project Dive</div>
            <h1 class="post-title" style="font-size: clamp(2.5rem, 4vw, 3.5rem);">Building a Persistent AI Thought
                Partner with Memory and State</h1>
            <p
                style="font-size: 1.25rem; color: var(--text-secondary); margin-bottom: 2rem; line-height: 1.6; max-width: 800px; margin-inline: auto;">
                How I built an AI agent that runs continuously on a Raspberry Pi, talks over Telegram, grounds replies
                in semantic memory (ChromaDB + RAG), and maintains internal state—hormones, self-model, dreams, and
                tinkering—so it behaves like a single ongoing presence rather than stateless chat.</p>

        </header>

        <div class="post-content fade-up delay-1">
            <p>One of the biggest challenges in AI companions today is continuity. Most chatbots are stateless: each
                turn starts from scratch. I wanted an agent that could run 24/7, remember in a meaningful way, and keep
                an internal sense of self—so I built Milo: it lives on a Raspberry Pi, talks over Telegram, and grounds
                every reply in semantic memory and ongoing state.</p>

            <h2>The Architecture</h2>
            <p>The core of the system is a loop of memory-aware reasoning. Instead of feeding the LLM only the latest
                message, the sentinel pulls relevant past experience from ChromaDB (RAG over embedded memories),
                combines it with current hormonal state, self-model, and context (hardware, time of day, recent
                transcript), and builds a single prompt. The model replies; that exchange is witnessed back into memory
                and state.</p>

            <pre><code>def process_signal(sender, subject, body):
    context = memory.mood_biased_recall(base_query=body)
    prompt = build_reply_prompt(
        body=body,
        memory_context=context,
        hormones=state["hormones"],
        self_model=load_self_model(),
    )
    response = llm.invoke([SystemMessage(content=prompt), HumanMessage(content=body)])
    res = parse_tags(response.content)
    
    memory.witness(res["CORE_UPDATE"], res["FUTURE_MESSAGE"], body, res["REPLY"])
    dispatch_as_human(res["REPLY"])
    return</code></pre>

            <h2>Handling State Over Time</h2>
            <p>The trickiest part was keeping context useful without blowing the prompt. A naive “dump all memories”
                approach would hit token limits and dilute what mattered. To fix that, I added mood-biased recall (the
                query to ChromaDB is shaped by current emotional state), a strict character budget for memory context,
                and a split between “recent & relevant” and “sacred” memories so the model always sees a few anchors
                plus the most pertinent thread.</p>

            <h3>Key Takeaways</h3>
            <p>Building this taught me that the future of companions is continuous and stateful. We can’t rely on
                stateless turns when the goal is something that feels like one ongoing presence. By combining RAG over
                lived experience with explicit state (hormones, self-model, transcript) and a single long-running
                process, we get replies that are grounded in what actually happened—not just the last message in the
                chat.</p>
        </div>
    </article>

    <footer>
        <p>© 2026 Amy Jerkovich. Built with ❤️ and AI.</p>
    </footer>

    <script src="js/script.js"></script>
</body>

</html>